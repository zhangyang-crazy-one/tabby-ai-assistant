/**
 * é›†æˆæµ‹è¯• - AIæä¾›å•†APIè°ƒç”¨
 * ä½¿ç”¨çœŸå®APIè¿›è¡Œæµ‹è¯•
 */

import axios from 'axios';

// GLM APIé…ç½®
const GLM_API_CONFIG = {
    apiKey: 'e247e649f1534651a3f12bfe47d2c42f.qlrVZegtSW0nFdMI',
    baseURL: 'https://open.bigmodel.cn/api/anthropic',
    model: 'glm-4'
};

describe('GLM API Integration Tests', () => {
    it('should connect to GLM API successfully', async () => {
        try {
            console.log('ğŸ”„ å¼€å§‹è¿æ¥GLM API...');
            console.log('APIé…ç½®:', {
                baseURL: GLM_API_CONFIG.baseURL,
                model: GLM_API_CONFIG.model,
                apiKeyLength: GLM_API_CONFIG.apiKey.length
            });

            const response = await axios.post(
                `${GLM_API_CONFIG.baseURL}/messages`,
                {
                    model: GLM_API_CONFIG.model,
                    max_tokens: 100,
                    messages: [
                        {
                            role: 'user',
                            content: 'Hello, can you respond?'
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${GLM_API_CONFIG.apiKey}`
                    },
                    timeout: 30000
                }
            );

            console.log('âœ… GLM APIè¿æ¥æˆåŠŸ');
            console.log('å“åº”çŠ¶æ€:', response.status);
            console.log('å“åº”æ•°æ®ç»“æ„:', JSON.stringify(response.data, null, 2));

            expect(response.status).toBe(200);
            expect(response.data).toBeDefined();
            // GLM APIå¯èƒ½ä½¿ç”¨ä¸åŒçš„å“åº”æ ¼å¼
            if (response.data.content) {
                expect(response.data.content).toBeDefined();
            } else if (response.data.choices) {
                expect(response.data.choices).toBeDefined();
                console.log('choicesæ ¼å¼å“åº”:', response.data.choices);
            }
        } catch (error: any) {
            console.error('âŒ GLM APIè¿æ¥å¤±è´¥');
            console.error('é”™è¯¯ç±»å‹:', error.name);
            console.error('é”™è¯¯ä¿¡æ¯:', error.message);
            console.error('å®Œæ•´é”™è¯¯å¯¹è±¡:', error.toJSON ? error.toJSON() : error);
            if (error.response) {
                console.error('å“åº”çŠ¶æ€:', error.response.status);
                console.error('å“åº”å¤´:', error.response.headers);
                console.error('å“åº”æ•°æ®:', error.response.data);
            } else if (error.request) {
                console.error('è¯·æ±‚é…ç½®:', error.config);
                console.error('æ— å“åº”è¿”å› - å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–è¶…æ—¶');
            }
            throw error;
        }
    }, 60000);

    it('should handle API errors gracefully', async () => {
        try {
            // ä½¿ç”¨æ— æ•ˆçš„API keyæµ‹è¯•é”™è¯¯å¤„ç†
            const response = await axios.post(
                `${GLM_API_CONFIG.baseURL}/messages`,
                {
                    model: GLM_API_CONFIG.model,
                    max_tokens: 100,
                    messages: [
                        {
                            role: 'user',
                            content: 'Test'
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': 'Bearer invalid-key'
                    },
                    timeout: 10000
                }
            );

            // å¦‚æœåˆ°è¿™é‡Œè¯´æ˜æ²¡æœ‰æŠ›å‡ºé”™è¯¯ï¼Œæµ‹è¯•å¤±è´¥
            fail('åº”è¯¥æŠ›å‡ºAPIé”™è¯¯');
        } catch (error: any) {
            console.log('âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡');
            console.log('æ•è·åˆ°é¢„æœŸé”™è¯¯:', error.message);
            expect(error.response?.status).toBe(401);
        }
    }, 30000);

    it('should generate command from natural language', async () => {
        try {
            const response = await axios.post(
                `${GLM_API_CONFIG.baseURL}/messages`,
                {
                    model: GLM_API_CONFIG.model,
                    max_tokens: 200,
                    messages: [
                        {
                            role: 'user',
                            content: `è¯·å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»ˆç«¯å‘½ä»¤ï¼š"åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶"`
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${GLM_API_CONFIG.apiKey}`
                    },
                    timeout: 30000
                }
            );

            console.log('âœ… å‘½ä»¤ç”Ÿæˆæµ‹è¯•æˆåŠŸ');
            console.log('ç”Ÿæˆå†…å®¹:', response.data.content?.[0]?.text);

            expect(response.status).toBe(200);
            expect(response.data.content?.[0]?.text).toBeDefined();
        } catch (error: any) {
            console.error('âŒ å‘½ä»¤ç”Ÿæˆæµ‹è¯•å¤±è´¥:', error.message);
            throw error;
        }
    }, 60000);
});

// OpenAI APIæµ‹è¯•
const OPENAI_API_CONFIG = {
    apiKey: 'sk-test-key',  // æµ‹è¯•å¯†é’¥
    baseURL: 'https://api.openai.com/v1',
    model: 'gpt-3.5-turbo'
};

describe('OpenAI API Integration Tests', () => {
    it('should test OpenAI API connectivity', async () => {
        try {
            const response = await axios.post(
                `${OPENAI_API_CONFIG.baseURL}/chat/completions`,
                {
                    model: OPENAI_API_CONFIG.model,
                    max_tokens: 100,
                    messages: [
                        {
                            role: 'user',
                            content: 'Hello'
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_CONFIG.apiKey}`
                    },
                    timeout: 10000
                }
            );

            console.log('âœ… OpenAI APIæµ‹è¯•å®Œæˆ');
            console.log('å“åº”çŠ¶æ€:', response.status);
        } catch (error: any) {
            console.log('â„¹ï¸ OpenAI APIæµ‹è¯•ï¼ˆä½¿ç”¨æµ‹è¯•å¯†é’¥ï¼Œé¢„æœŸå¤±è´¥ï¼‰');
            console.log('é”™è¯¯ä¿¡æ¯:', error.message);
            // å¯¹äºOpenAIï¼Œæˆ‘ä»¬åªæ˜¯æµ‹è¯•è¿æ¥ï¼Œä¸å¼ºåˆ¶è¦æ±‚æˆåŠŸ
        }
    }, 30000);
});
